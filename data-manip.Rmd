```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```
# Data Manipulation {#data-manip}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In sensory science, different data collection tools (whether it is device, software, or methodologies) may provide data in different formats. Also, different statistical analyses may require having the same data but structured differently. 

A simple example to illustrate this later point is the analysis of liking data.
Let C consumers provide their hedonic assessments of P samples. To evaluate if samples have been liked differently, an ANOVA is performed on a long thin table with (PxC) rows x 3 columns (consumer, sample, and the liking scores). However, to assess whether consumers have the same preference patterns at the indidual level, internal preference mapping or cluster analysis would be performed, and both these analyses require as input a short and large table with P rows and C columns. 

Another example of data manipulation consists in summarizing data, by for instance computing the mean by product for each sensory attribute (hence creating the so-called sensory profiles), or to generate frequency tables (e.g. proportions of male/female, distribution of the liking scores by sample, contingency table for CATA data, etc.)

For these reasons, it is hence essential to learn to manipulate data and transition from one structure to another one.

For illustration, let's consider some sensory data stored in *Sensory Profile.xlsx*, which consists in 9 panellists evaluating 11 samples on 32 sensory attributes.

We importing this data using the `read_xlsx()` function from the `{readxl}` package (for more information on how to import data, see Section \@ref(data-collection)).

```{r import, echo=FALSE}
library(tidyverse)
library(readxl)
library(here)

file_path <- here("data","Sensory Profile.xlsx") 
sensory <- read_xlsx(file_path, sheet="Data")
sensory
```

A first analysis that is commonly done on such table consists in computing the mean per sample for each attribute, hence generating the so-called sensory profiles of the samples. Such table (crossing the samples in rows and the sensory attributes in columns) gives a first impression at the differences between samples across attributes. 

The principles of data manipulation will be illustrated here by generating the sensory profiles from the raw data using different approaches. This step consists in reducing the 99x35 table into a 11x32 table, i.e. a table with 11 rows (one per sample) and 32 columns (one per attribute). Note that here, we consider the sample information as row names, not as an extra column in the dataset, else we would have a 11x33 table.

<!-- 
1. Using base R and 'regular' functions
2. `{SensoMineR}`, a package dedicated to sensory analysis
3. A different approach proposed by Hadley Wickham and his team at RStudio using the `{tidyverse}` philosophy, philosophy that we will be adopting throughout this book.

### Using `{base}`

To compute the mean, the `mean()` function is used: It computes the mean across a set of values. Unfortunately, it is not possible to specify a variable to split the mean for the different categories. In other words, applying `mean()` to a variable would provide the grand mean, not the mean per sample.  
To create the sensory profiles, a first possibility consists in filtering the data by product, and computing the mean in each case. The results obtained for each sample are then combined. Although this solution works, it is quite tedious, and we are not going to consider it here. Instead, we propose to combine `mean()` to the `aggregate()` function: `aggregate()` allows performing the same function (here `mean()`) across a set of variables by splitting the results according to one (or more) categorical variables specified by `by`. In our example, such table would be obtained as such:

```{r mean_aggregate}
senso_mean1 <- aggregate(sensory[,4:ncol(sensory)], by=list(sensory[,3]), FUN=mean)
rownames(senso_mean1) <- senso_mean1[,1]
senso_mean1 <- senso_mean1[,-1]
round(senso_mean1, 2)
```

In case we would have replicates and would want to compute the mean across replicates (hence generate a (panelist x sample) x attribute table), we would use `by=c(list(sensory[,1], list(sensory[,2])))`. Many other functions could also be used here: Instead of `mean()`, one could consider `median()`, `min()`, `max()`, or eventually `length()` to evaluate how many scores each samples received.

### Using `{SensoMineR}`

Alternatively to base R, we can also consider the `averagetable()` function from the **{SensoMineR}** package.  Since **{SensoMineR}** is a package dedicated to the analysis of sensory data, it is no surprise that it provides such possibility. In this case, the code would look like the following:

```{r averagetable}
library(SensoMineR)
senso_adjmean1 <- averagetable(sensory, formul="~product+judge", firstvar=4, method="mean")
round(senso_adjmean1, 2)
```

The `averagetable()` has the disadvantage that it can only compute the mean, meaning that this function cannot be provide other statistics such as the median for instance. However, when the dataset contains missing data (visible through empty cells in the data, or invisible through incomplete design), this function allows computing both the arithmetic mean and the adjusted mean[^1] (also known as LS means) through the `method` option (use `method="coeff"` for the adjusted mean). 

[^1]: The adjusted mean (or LS mean) consists in estimating through a model the missing values before computing the mean. When there are no missing data, both the arithmetic mean and the adjusted mean return the same results. 

The adjusted mean can also be obtained from the `SensoMineR::decat()` (which stands for DEscription of CATegories) function, which goes further in the description of the samples since ANOVA and t-tests are also performed. To extract the sensory profiles, the output called `adjmean` is extracted.

```{r decat}
senso_adjmean2 <- decat(sensory, formul="~product+judge", firstvar=4, graph=FALSE)$adjmean
round(senso_adjmean2, 2)
```

-->

### Using the `{tidyverse}`

Although the solutions we just presented are simple and only involve a few lines of code, we propose other solutions using the **{tidyverse}**.  This will allow us introducing this philosophy of coding, and will provide you a first contact to some of the functions that we use. It will also show you that each situation can be solved in different ways, hence opening your mind and stimulating your creative imagination.

The **{tidyverse}** operates 5 major transformations on a dataset:

- `select()` allows selecting, renaming, and re-arranging columns of a dataset;
- `filter()` and `arrange()` works on the rows of the dataset by filtering data and rearranging the order;
- `mutate()` adds new columns, which can be the combination of other columns of the dataset;
- `summarise()` summarises the data by providing the statistics of interest on the variables selected (all the variables that are not specified are then removed).

Note that for `mutate()` and `summarise()`, different variant such as `mutate_all()` or `mutate_if()` (resp. `summarise_all()` and `summarise_if()`) allows applying the same transformation to multiple columns (all the columns for `mutate_all()` and `summarise_all()`, or the one that meet a pre-defined condition for `mutate_if()` and `summarise_if()`).

As a first proposition, we use `summarise_all`, meaning that we should only keep the variables that are relevant for the analysis. From `sensory`, we hence select the columns 3 (product), and the block starting from column 4 until the end of the dataset (sensory attributes).
Since the mean needs to be computed for each sample separately, the function `group_by()` is  used. This function ensures that the results are summarised by product in our case. We then summarise the data by performing the mean on all the variables (product is ignored since it is used to group the results).
Ultimately, we use the product names as row names (using `column_to_rownames()`).

```{r summarise_all}
senso_mean2 <- sensory %>% 
  dplyr::select(3,4:ncol(sensory)) %>% 
  group_by(product) %>% 
  summarise_all(list(~mean(.))) %>% 
  column_to_rownames(var="product")
round(senso_mean2, 2)
```

The transformation from the original 11x35 table to the 11x33 table is done through the `group_by()` followed by `summarise_all` functions.

Another way of generating such table consists in not pre-selecting the variables, but in computing the mean only if the variable is numerical. To do so, we use `summarise_if()` and we put the condition that the variable should be numerical to compute the mean (otherwise R will return an error). Here again, we group the results by product.

```{r summarise_if}
senso_mean3 <- sensory %>% 
  group_by(product) %>% 
  summarise_if(is.numeric, mean) %>% 
  column_to_rownames(var="product")
round(senso_mean3, 2)
```

This solution fits well if all the variables that are numeric should be summarized in the same way (here using the mean). Otherwise, a good solution is to run the analysis on a pre-defined set of variables. Such set can be created manually (we are taking the first 10 sensory attributes here), or automatically if the names of the attributes follow a certain pattern. In such case, the use of functions such as `starts_with()`, `ends_with()`, or using regular expression is of great help!

The mean table is then generated using the `summarise()` function `across()` `all_of()` the variables that were selected.

```{r across}
senso_var <- colnames(sensory)[4:13]
senso_mean4 <- sensory %>% 
  group_by(product) %>% 
  summarise(across(all_of(senso_var), mean)) %>% 
  as.data.frame() %>% 
  column_to_rownames(var="product")
round(senso_mean4, 2)
```

At last, we propose a solution which in this case is not optimal, but which can be very useful in some others. This solution consists in working on the dataset by permuting all the variables using `pivot_longer()`, hence generating a dataset with 3 relevant columns: one containing the products, one containing all the attributes, and one containing the scores. On this variable, we `summarise()` the scores by product and by attribute, before re-structuring the data using `pivot_wider()`.
Note that the combination `pivot_longer()` and `pivot_wider()` will re-organize automatically the attributes alphabetically. To avoid that, we can transform the column we name `attribute` into a factor with as level order the original order. This procedure maintains the original order.

```{r pivot}
senso_mean5 <- sensory %>% 
  pivot_longer(4:ncol(.), names_to="attributes", values_to="scores") %>% 
  mutate(attributes = factor(attributes, levels=colnames(sensory)[4:ncol(sensory)])) %>% 
  group_by(product, attributes) %>% 
  summarise(scores = mean(scores)) %>% 
  pivot_wider(names_from=attributes, values_from=scores) %>% 
  column_to_rownames(var="product")
round(senso_mean5, 2)
```

This procedure uses intermediate steps since the structure of the original table (99x35) is transformed by pivoting the attributes from columns to rows: this means that after `pivot_wider()`, the dataset created now contains 99x32=3168 rows and 5 columns (*judge*, *code*, and *product*, one column called *attributes* which contains the attribute names, and one column called *scores* which contain the individual scores). This table is then reduced to a table 11x32=352 rows and 3 columns (*product*, *attributes*, *scores*) through the `group_by()` and `summarise()` process, before being reset as 11x33 table through `pivot_wider()`.

This procedure could slightly be simplified: To generate `senso_mean5`, we computed the mean by `product` and `attributes` across all assessors. If we delete this line of code (i.e. related to `summary`), R will generate a table crossing `product` in rows, `attributes` in columns, in which each cell contains a list of values (here, we have as many values as we have assessors performing the test in each cell).
When such situation appears, it is possible to apply automatically a function (here we want the `mean()`) on this sets of values using `values_fn` from `pivot_wider()`.

```{r pivot values_fn}
senso_mean6 <- sensory %>% 
  pivot_longer(4:ncol(.), names_to="attribute", values_to="scores") %>% 
  mutate(attribute = factor(attribute, levels=colnames(sensory)[4:ncol(sensory)])) %>% 
  dplyr::select(-judge, -code) %>% 
  group_by(product, attribute) %>% 
  pivot_wider(names_from=attribute, values_from=scores, values_fn=mean) %>% 
  column_to_rownames(var="product")
round(senso_mean6, 2)
```

In a similar way, missing values can be replaced automatically using `values_fill`.

As expected, all these solutions provide the same sensory profiles using different process. Depending on the situations, some of these processes may be better than others.

Note that multiple analysis can be ordered together. Let's take back the example generating `senso_mean4`, and let's consider 2 other groups of variables, one in which we ask for the median, and one for which we ask the number of measures. This entire table can be generated as such:

```{r across bis}
senso_var1 <- colnames(sensory)[4:13]
senso_var2 <- colnames(sensory)[14:20]
senso_var3 <- colnames(sensory)[21:25]

senso_multifun <- sensory %>% 
  group_by(product) %>% 
  summarise(across(all_of(senso_var1), mean),
            across(all_of(senso_var2), median),
            across(all_of(senso_var3), length)) %>% 
  as.data.frame() %>% 
  column_to_rownames(var="product")
round(senso_multifun, 2)
```

