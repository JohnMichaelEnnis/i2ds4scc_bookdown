# What is Data Science? {#data_science}

In this chapter we explain what is data science.

## History and Definition

Data science has been called the "sexiest job of the 21st century" by Harvard Business Review [insert DJ Patil reference], but what is it?  As with all rapidly growing fields, the definition depends on who you ask.  Before we give our definition, however, we provide a brief history for context.

To begin, we note that there was a movement in early computer science to call their field "data science."  Chief among the advocates for this viewpoint was Peter Naur, winner of the 2005 Turing award.  This viewpoint is detailed in the preface to his 1974 book, "Concise Survey of Computer Methods," where he states that data science is "the science of dealing with data, once they have been established."  From his perspective, this is the purpose of computer science.  This viewpoint is echoed in the statement, often attributed to Edsger Dijkstr, that "Computer science is no more about computers than astronomy is about telescopes."

Interestingly, a similar movement arose in statistics, starting in 1962 with John Tukey's statements that "Data analysis, and the parts of statistics which adhere to it, must ... take on the characteristics of science rather than those of mathematics" and that "data analysis is intrinsically an empirical science."  This movement culminated in 1997 when Jeff Wu proposed during his inaugural lecture, upon becoming the chair of the University of Michigan's statistics department, that statistics should be called data science.

These two movements came together in 2001 in William S. Cleveland's paper "Data Science: An Action Plan for Expanding the Technical Areas in the Field of Statistics."  In this highly influential monograph, Cleveland makes the key assertion that "The value of technical work is judged by the extent ot which it benefits the data analyst, either directly or indirectly."  

[FOOTNOTE: It is worth noting that these two movements were connected by substantial work in the areas of statistical computing, knowledge discovery, and data mining, with important work contributed by Gregory Piatetsky-Shapiro, Usama Fayyad, and Padhraic Smyth among many others.]

Putting this history together, we provide our definition of **data science** as: The intersection of statistics, computer science, and industrial design.  Accordingly, we use the following three definitions of these fields:

- **Statistics**: The branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data.
- **Computer Science**: Computer science is the study of processes that interact with data and that can be represented as data in the form of programs.
- **Industrial Design**: The professional service of creating and developing concepts and specifications that optimize the function, value, and appearance of products and systems for the mutual benefit of both user and manufacturer.

Hence data science is the production of useful things through the collection, processing, analysis, and interpretation of data.

## Workflow

A schematic of a data scientific workflow is shown in Figure \@ref(fig:ds-workflow).  Each section is described in greater detail below.

```{r ds-workflow, fig.cap='Data scientific workflow.', fig.align='center', echo=FALSE}

knitr::include_graphics("images/data_science_workflow.png")

```

### Data Preparation

#### Inspect

Goal: 
Gain familiarity with the data
Key Steps:
Learn collection details
Check data imported correctly
Determine data types
Ascertain consistency and validity
Tabulate and compute other basic summary statistics
Create basic plots of key variables of interest


#### Clean

Goal: 
Prepare data for analysis
Key Steps:
Remove/correct errors
Make data formatting consistent
Organize text data
Create tidy data (one observation per row)
Organize data into related tables
Document all choices


### Data Analysis

#### Transform

Goal: 
Adjust data as needed for analysis
Key Steps:
Create secondary variables
Decorrelate data
Identify latent factors
Engineer new features


#### Explore

Goal: 
Allow data to suggest hypotheses
Key Steps:
Graphical visualizations
Exploratory analyses
Note:
Caution must be taken to avoid high false discovery rate when using automated tools


#### Model

Goal: 
Conduct formal statistical modeling
Key Steps:
Conduct traditional statistical modeling
Build predictive models
Note:
This step may feed back into transform and explore


### Insight Delivery

#### Communicate

Goal: 
Exchange research information
Key Steps:
Automate reporting as much as possible
Share insights
Receive feedback
Note:
Design principles essential to make information accessible


#### Reformulate

Goal: 
Incorporate feedback into workflow
Key Steps:
Investigate new questions
Revise communications
Note:
Reformulation make take us back to data cleaning


## Benefits of Data Science

### Reproducible Research
- Time savings
- Collaboration
- Continuous improvement
  
### Data-Driven Decision Making
### Standardized Data Collection
### Standardized Reporting
- Especially valuable when there are multiple sites globally
  
### Improved Business Impact

## How to Learn Data Science

Learning data science is much like learning a language or learning to play an instrument - you have to practice.  Our advice based on mentoring many students and clients is to get started sooner rather than later, and to accept that the code you'll write in the future will always be better than the code you'll write today.  Also, many of the small details that separate an proficient data scientist from a novice can only really be learned through practice as there are too many small details to learn them all in advice.  So, starting today, do your best to write at least some code for all your projects.  If a time deadline prevents you from completing the analysis in R, that's fine, but at least gain the experience of making an RStudio project and loading the data in R.  Then, as time allows, try to duplicate your analyses in R, being quick to search for solutions when you run into errors.  Often simply copying and pasting your error into a search engine will be enough to find the solution to your problem.  Moreover, searching for solutions is its own skill that also requires practice.  Finally, if you are really stuck, reach out to a colleague (or even the authors of this book) for help

## How to Use This Book

We recommend following the instructions in Chapter \@ref(start-R) to get started.

## Common Data Science Tools

## Why R?

For sensory and consumer scientists, we recommend the R ecosystem of tools for three main reasons.  The first reason is cultural - R has from its inception been oriented more towards statistics than to computer science, making the feeling of programming in R more natural (in our experience) for sensory and consumer scientists than programming in Python.  This opinion of experience is not to say that a sensory and consumer scientist shouldn't learn Python if they are so inclined, or even that Python tools aren't sometimes superior to R tools (in fact, they sometimes are).  This latter point leads to our second reason, which is that R tools are typically better suited to sensory and consumer science than are Python tools.  Even when Python tools are superior, the R tools are still sufficient for sensory and consumer science purposes, plus there are many custom packages such as SensR, SensoMineR, and FactorMineR that have been specifically developed for sensory and consumer science.  Finally, the recent work by the RStudio company, and especially the exceptional work of Hadley Wickham, has lead to a very low barrier to entry for programming within R together with exceptional tools for data manipulation.

We continue our discussion of getting started with R in the next chapter.
  

