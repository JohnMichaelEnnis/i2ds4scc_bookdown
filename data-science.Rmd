```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```
# What is Data Science? {#data_science}

In this chapter we explain what is data science.  We will also talk about diverse data being the best part sensory science.

## History and Definition

You may know that data science has been called the "sexiest job of the 21st century" by Harvard Business Review.  But what is data science?  As with all rapidly growing fields, the definition depends on who you ask.  Before we give our definition, however, we provide some brief history for context.

To begin, there was a movement in early computer science to call their field "data science."  Chief among the advocates for this viewpoint was Peter Naur, winner of the 2005 Turing award (a prize roughly equivalent in prestige to a Nobel prize, but for computer science).  This viewpoint is detailed in the preface to his 1974 book, "Concise Survey of Computer Methods," where he states that data science is "the science of dealing with data, once they have been established."  [Reference Naur] According to Naur, this is the purpose of computer science.  This viewpoint is echoed in the statement, often attributed to Edsger Dijkstr, that "Computer science is no more about computers than astronomy is about telescopes."  [Reference Naur]

Interestingly, a similar viewpoint arose in statistics, as reflected in John Tukey's statements that "Data analysis, and the parts of statistics which adhere to it, must ... take on the characteristics of science rather than those of mathematics" and that "data analysis is intrinsically an empirical science." [REFERENCE] This movement culminated in 1997 when Jeff Wu proposed during his inaugural lecture, upon becoming the chair of the University of Michigan's statistics department, that statistics should be called data science. [REFERENCE]

These two movements came together in 2001 in William S. Cleveland's paper "Data Science: An Action Plan for Expanding the Technical Areas in the Field of Statistics."  In this highly influential monograph, Cleveland makes the key assertion that "The value of technical work is judged by the extent ot which it benefits the data analyst, either directly or indirectly."  

[FOOTNOTE: It is worth noting that these two movements were connected by substantial work in the areas of statistical computing, knowledge discovery, and data mining, with important work contributed by Gregory Piatetsky-Shapiro, Usama Fayyad, and Padhraic Smyth among many others.]

Putting this history together, we provide our definition of **data science** as: The intersection of statistics, computer science, and industrial design.  Accordingly, we use the following three definitions of these fields:

- **Statistics**: The branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data.
- **Computer Science**: Computer science is the study of processes that interact with data and that can be represented as data in the form of programs.
- **Industrial Design**: The professional service of creating and developing concepts and specifications that optimize the function, value, and appearance of products and systems for the mutual benefit of both user and manufacturer.

Hence data science is the delivery of value through the collection, processing, analysis, and interpretation of data.

## Benefits of Data Science

### Data-Driven Decision Making
### Standardized Data Collection
### Standardized Reporting
- Especially valuable when there are multiple sites globally
  
### Improved Business Impact

## Data Scientific Workflow

A schematic of a data scientific workflow is shown in Figure \@ref(fig:ds-workflow).  Each section is described in greater detail below.

```{r ds-workflow, fig.cap='Data scientific workflow.', fig.align='center', echo=FALSE, eval=TRUE}

knitr::include_graphics("images/data_science_workflow.png")

```

### Data Collection {#data-collection2}

#### Design

#### Execute

#### Import

### Data Preparation

#### Inspect

Goal: 
Gain familiarity with the data
Key Steps:
Learn collection details
Check data imported correctly
Determine data types
Ascertain consistency and validity
Tabulate and compute other basic summary statistics
Create basic plots of key variables of interest


#### Clean

Goal: 
Prepare data for analysis
Key Steps:
Remove/correct errors
Make data formatting consistent
Organize text data
Create tidy data (one observation per row)
Organize data into related tables
Document all choices


### Data Analysis {#data-analysis2}

#### Transform

Goal: 
Adjust data as needed for analysis
Key Steps:
Create secondary variables
Decorrelate data
Identify latent factors
Engineer new features


#### Explore

Goal: 
Allow data to suggest hypotheses
Key Steps:
Graphical visualizations
Exploratory analyses
Note:
Caution must be taken to avoid high false discovery rate when using automated tools


#### Model

Goal: 
Conduct formal statistical modeling
Key Steps:
Conduct traditional statistical modeling
Build predictive models
Note:
This step may feed back into transform and explore

### Value Delivery {#value-delivery2}

#### Communicate

Goal: 
Exchange research information
Key Steps:
Automate reporting as much as possible
Share insights
Receive feedback
Note:
Design principles essential to make information accessible


#### Reformulate

Goal: 
Incorporate feedback into workflow
Key Steps:
Investigate new questions
Revise communications
Note:
Reformulation make take us back to data cleaning

## Reproducible Research

Discuss benefits

- Time savings
- Collaboration
- Continuous improvement


## How to Learn Data Science

Learning data science is much like learning a language or learning to play an instrument - you have to practice.  Our advice based on mentoring many students and clients is to get started sooner rather than later, and to accept that the code you'll write in the future will always be better than the code you'll write today.  Also, many of the small details that separate an proficient data scientist from a novice can only really be learned through practice as there are too many small details to learn them all in advice.  So, starting today, do your best to write at least some code for all your projects.  If a time deadline prevents you from completing the analysis in R, that's fine, but at least gain the experience of making an RStudio project and loading the data in R.  Then, as time allows, try to duplicate your analyses in R, being quick to search for solutions when you run into errors.  Often simply copying and pasting your error into a search engine will be enough to find the solution to your problem.  Moreover, searching for solutions is its own skill that also requires practice.  Finally, if you are really stuck, reach out to a colleague (or even the authors of this book) for help

We recommend following the instructions in Appendix \@ref(start-R) to get started.


